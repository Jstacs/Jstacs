<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
<head>
<!--
/*
 * This file is part of Jstacs.
 *
 * Jstacs is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 * 
 * Jstacs is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with Jstacs.  If not, see <http://www.gnu.org/licenses/>.
 * 
 * For more information on Jstacs, visit http://www.jstacs.de
 */
-->
</head>
<body bgcolor="white">

This package allows to assess classifiers.<br><br>
It contains the class <code>ClassifierAssessment</code> that
is used as a super-class of all implemented methodologies of
an assessment to assess classifiers. In addition it should be
used as a super-class of all coming assessments since this
class already implements basic patterns like:
<ul>
<li> handling of given classifiers
<li> handling of given models and construction of classifiers using those models
<li> management of temporary results (In general an assessment is a repeated
procedure producing several temporary results that are summarized in terms of
means or standard deviations or standard-errors.)
<li> construction of a summary (mean and standard-error of temporary results)
</ul>
<br><br>
Further on it contains three implementations of different
assessments to assess classifiers. These are:
<ul>
<li> Repeated HoldOut Experiment 
<li> Sampled Repeated HoldOut Experiment 
<li> K-Fold Crossvaliation
<li> Repeated Subsampling Experiment
</ul>
<br><br>
A <code>RepeatedHoldOutExperiment</code> implements the following procedure.
For given data-sets it randomly, mutually exclusive partitions the given data-sets
into a train-data-set and a test-data-set. Afterwards it uses these data-sets to first
train the classifiers and afterwards assess its performance to correctly predict
the elements of the test-data-sets. This step is repeated at users will.
<br><br>
A <code>Sampled_RepeatedHoldOutExperiment</code> is a special ClassifierAssessment
that partitions the data of a user-specified reference class and data sets non-overlapping
for all other classes, so that one gets the same number of sequences (and the same
lengths of the sequences) in each train and test data set. 
<br><br>
A <code>KFoldCrossValidation</code> implements a k-fold crossvalidation. That is
the given data is randomly and mutually exclusive partitioned into k parts.
Each of these parts is used once as test-data-set and the remaining k-1 
parts are used once as train-data-sets. In each of the k steps the classifiers
are trained using the train-data-sets and their performance to correctly predict
the elements of the test-data-sets is assessed.
<br><br>
A <code>RepeatedSubSamplingExperiment</code> subsamples in each step
a train-data-set and a test-data-set from given data. These data-sets
may be overlapping. Afterwards the classifiers are trained using the
train-data-sets and their performance to predict the elements of the
test-data-sets is assessed. This procedure is repeated at users will.
<br><br>
In addition all classes allow to assess classifiers using a set of
user-specified test-data-sets and a set of user specified train-data-sets.
This methodology allows the user to use test- and train-data-sets
that are not automatically generated but user-specified.

<!-- Put @see and @since tags down here. -->

</body>
</html>
